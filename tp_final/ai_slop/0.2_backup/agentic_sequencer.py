#!/usr/bin/env python3
"""
Agentic Microsample Music System (from scratch)

Goals:
- Agentic at its core: form, memory, self-evaluation, and adaptive behavior.
- Event-based (not a hard step sequencer): onsets are generated by a policy (point-process-like),
  optionally "magnetized" to a soft pulse for groove, but never locked to a fixed grid.
- Minimal user arguments: audio settings, channel count, DB sample limit, random seed.
- Deterministic behavior with a single seed (reproducible runs).
- Multi-channel output supported (mono / stereo / quad).
- One JSON per run log: segments (form sections) with metadata + events.

Architecture:
- SampleDatabase -> loads samples deterministically from SQLite and disk
- FeatureExtractor -> lightweight features for palette/timbre control
- Clusterer -> per-stem clustering (dynamic K) for palette cohesion/contrast
- RunLogger -> one file per run, segments with metadata then events
- GlobalState/Director/Critic/Memory -> agentic brain (form + feedback + motifs)
- Voices -> per-stem generative policies (choose next onset + sample + articulation)
- PlannerThread -> schedules rendered audio events ahead of time (lookahead)
- AudioEngine -> mixes scheduled buffers sample-accurately with sounddevice
"""

import os
import sys
import math
import json
import time
import heapq
import sqlite3
import random
import threading
import argparse
from pathlib import Path
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, Callable
from collections import deque, Counter

try:
    import tkinter as tk
    from tkinter import ttk
    _TK_AVAILABLE = True
except Exception:
    _TK_AVAILABLE = False

import numpy as np
import soundfile as sf
import sounddevice as sd


# -------------------- CLI (minimal) --------------------
def parse_arguments():
    p = argparse.ArgumentParser(description="Agentic Microsample Music System")

    # I/O
    p.add_argument("--db-path", default="microsamples.db", help="SQLite database path")
    p.add_argument("--samples-dir", default="samples", help="Directory containing sample files")
    p.add_argument("--samples-limit", type=int, default=800, help="Max samples per stem type loaded from DB")

    # Audio
    p.add_argument("--channels", type=int, choices=[1, 2, 4], default=2, help="Output channels: 1/2/4")
    p.add_argument("--sr", type=int, default=44100, help="Sample rate")
    p.add_argument("--blocksize", type=int, default=1024, help="Audio block size")
    p.add_argument("--latency", default="high", help="sounddevice latency setting")

    # Determinism
    p.add_argument("--seed", type=int, default=None, help="Random seed for reproducibility")

    return p.parse_args()


# -------------------- Channel mapping --------------------
def channel_map_for(output_channels: int) -> Dict[str, int]:
    if output_channels == 1:
        return {"drums": 0, "bass": 0, "other": 0, "vocals": 0}
    if output_channels == 2:
        return {"drums": 0, "bass": 0, "other": 1, "vocals": 1}
    return {"drums": 0, "bass": 1, "other": 2, "vocals": 3}


# -------------------- DSP helpers --------------------
def semitone_to_ratio(semitones: float) -> float:
    return 2.0 ** (semitones / 12.0)


def resample_linear(signal: np.ndarray, ratio: float) -> np.ndarray:
    """Fast linear resampling; ratio = src_sr / dst_sr (or pitch ratio)."""
    if ratio == 1.0:
        return signal
    n = signal.shape[0]
    new_n = int(max(1, math.floor(n / ratio)))
    old_idx = np.arange(new_n) * ratio
    i0 = np.floor(old_idx).astype(int)
    frac = old_idx - i0
    i1 = np.minimum(i0 + 1, n - 1)

    if signal.ndim == 1:
        return (1 - frac) * signal[i0] + frac * signal[i1]
    out = np.zeros((new_n, signal.shape[1]), dtype=signal.dtype)
    for c in range(signal.shape[1]):
        out[:, c] = (1 - frac) * signal[i0, c] + frac * signal[i1, c]
    return out


def to_mono(x: np.ndarray) -> np.ndarray:
    if x.ndim > 1:
        return np.mean(x, axis=1)
    return x


def apply_fade(signal: np.ndarray, fade_samples: int) -> np.ndarray:
    if signal.shape[0] <= 1 or fade_samples <= 0:
        return signal
    n = signal.shape[0]
    f = min(fade_samples, n // 2)
    if f <= 0:
        return signal
    fade_in = np.linspace(0.0, 1.0, f, dtype=np.float32)
    fade_out = np.linspace(1.0, 0.0, f, dtype=np.float32)
    signal[:f] *= fade_in
    signal[-f:] *= fade_out
    return signal


def lowpass_1pole(signal: np.ndarray, cutoff_hz: float, sr: int) -> np.ndarray:
    """Simple 1-pole lowpass; lightweight for real-time."""
    x = to_mono(signal).astype(np.float32, copy=False)
    cutoff = float(np.clip(cutoff_hz, 30.0, sr * 0.45))
    # RC filter
    dt = 1.0 / sr
    rc = 1.0 / (2.0 * math.pi * cutoff)
    a = dt / (rc + dt)
    y = np.empty_like(x)
    acc = 0.0
    for i in range(len(x)):
        acc = acc + a * (x[i] - acc)
        y[i] = acc
    return y


def soft_clip(x: np.ndarray, drive: float) -> np.ndarray:
    y = x * drive
    y = np.tanh(y)
    return y.astype(np.float32, copy=False)


def envelope_perc(length: int, sr: int, attack_s: float, release_s: float) -> np.ndarray:
    """Simple percussive envelope; fully dynamic from state."""
    a = max(1, int(round(attack_s * sr)))
    r = max(1, int(round(release_s * sr)))
    n = length
    env = np.ones(n, dtype=np.float32)
    a = min(a, n)
    env[:a] = np.linspace(0.0, 1.0, a, dtype=np.float32)
    # release from end
    r = min(r, n)
    env[-r:] *= np.linspace(1.0, 0.0, r, dtype=np.float32)
    return env


# -------------------- Data model --------------------
@dataclass
class Sample:
    data: np.ndarray
    sr: int
    filename: str
    name: str
    stem_type: str
    position: float
    duration: float
    meta: Dict[str, Any] = field(default_factory=dict)
    features: Dict[str, float] = field(default_factory=dict)
    cluster_id: int = -1


@dataclass
class RenderParams:
    gain: float
    semitone: float
    lowpass_hz: float
    reverse: bool
    drive: float
    fade_s: float
    env_attack_s: float
    env_release_s: float


@dataclass
class ScheduledAudio:
    start_sample: int
    channel: int
    buffer: np.ndarray
    # for logging/inspection:
    event_meta: Dict[str, Any] = field(default_factory=dict)


@dataclass
class PlayEvent:
    """Active audio event in the mixer, with sample-accurate delay before it starts."""
    buffer: np.ndarray
    channel: int
    pos: int = 0
    delay: int = 0  # samples of silence before playback begins


# -------------------- Sample database --------------------
class SampleDatabase:
    def __init__(self, db_path: str, samples_dir: str, rng: random.Random):
        self.db_path = db_path
        self.samples_dir = samples_dir
        self.rng = rng
        self.conn = sqlite3.connect(db_path)

    def load_by_stem(self, stem_type: str, limit: int) -> List[Sample]:
        cur = self.conn.cursor()
        # Deterministic ordering; we shuffle deterministically after fetch.
        cur.execute(
            """
            SELECT sample_filename, stem_type, sample_position, duration, metadata_json
            FROM samples
            WHERE stem_type = ?
            ORDER BY sample_filename ASC
            """,
            (stem_type,),
        )
        rows = cur.fetchall()
        self.rng.shuffle(rows)
        rows = rows[: max(0, int(limit))]

        out: List[Sample] = []
        for (fn, st, pos, dur, meta_json) in rows:
            path = os.path.join(self.samples_dir, fn)
            if not os.path.exists(path):
                continue
            try:
                data, sr = sf.read(path, always_2d=False)
                data = np.asarray(data, dtype=np.float32)
                meta = json.loads(meta_json) if meta_json else {}
                name = f"{meta.get('artist', 'Unknown')} - {meta.get('song_title', 'Unknown')} - {st}"
                duration = float(dur) if dur is not None else float(len(data) / max(1, sr))
                out.append(
                    Sample(
                        data=data,
                        sr=int(sr),
                        filename=str(fn),
                        name=name,
                        stem_type=str(st),
                        position=float(pos) if pos is not None else 0.0,
                        duration=duration,
                        meta=meta,
                    )
                )
            except Exception:
                continue
        return out

    def close(self):
        try:
            self.conn.close()
        except Exception:
            pass


# -------------------- Feature extraction + clustering --------------------
class FeatureExtractor:
    """Lightweight timbral proxies for agentic control (brightness/noisiness/duration)."""
    def __init__(self, sr_target: int):
        self.sr_target = sr_target

    def extract(self, s: Sample) -> Dict[str, float]:
        x = to_mono(s.data)
        if s.sr != self.sr_target:
            x = resample_linear(x, s.sr / self.sr_target)
        n = min(len(x), self.sr_target)  # analyze up to 1s
        x = x[:n].astype(np.float32, copy=False)
        if n < 32:
            return {"rms": 0.0, "zcr": 0.0, "centroid": 0.0, "dur": float(s.duration)}

        rms = float(np.sqrt(np.mean(x * x) + 1e-12))
        zcr = float(np.mean(np.abs(np.diff(np.signbit(x))).astype(np.float32)))

        win = np.hanning(n).astype(np.float32)
        X = np.fft.rfft(x * win)
        mag = np.abs(X).astype(np.float32) + 1e-12
        freqs = np.fft.rfftfreq(n, d=1.0 / self.sr_target).astype(np.float32)
        centroid = float(np.sum(freqs * mag) / np.sum(mag))

        return {"rms": rms, "zcr": zcr, "centroid": centroid, "dur": float(s.duration)}


class KMeansLite:
    def __init__(self, k: int, iters: int, rng: random.Random):
        self.k = max(1, int(k))
        self.iters = max(1, int(iters))
        self.rng = rng

    def fit_predict(self, X: np.ndarray) -> np.ndarray:
        n = X.shape[0]
        if n == 0:
            return np.zeros((0,), dtype=np.int32)
        k = min(self.k, n)

        idx = list(range(n))
        self.rng.shuffle(idx)
        centers = X[idx[:k]].copy()

        labels = np.zeros((n,), dtype=np.int32)
        for _ in range(self.iters):
            d2 = ((X[:, None, :] - centers[None, :, :]) ** 2).sum(axis=2)
            new_labels = np.argmin(d2, axis=1).astype(np.int32)
            if np.array_equal(new_labels, labels):
                break
            labels = new_labels
            for j in range(k):
                mask = labels == j
                if np.any(mask):
                    centers[j] = X[mask].mean(axis=0)
                else:
                    centers[j] = X[self.rng.randrange(n)]
        return labels


class Clusterer:
    """Per-stem clustering with dynamic K (not hardcoded to a fixed number)."""
    def __init__(self, rng: random.Random):
        self.rng = rng

    @staticmethod
    def _dynamic_k(n: int) -> int:
        # "Dynamic" heuristic: grows with sqrt(n), capped gently to avoid overfragmentation.
        if n <= 8:
            return 1
        return int(np.clip(round(math.sqrt(n)), 2, 10))

    def assign(self, samples_by_stem: Dict[str, List[Sample]]):
        for stem, samples in samples_by_stem.items():
            if not samples:
                continue
            feats = []
            for s in samples:
                f = s.features
                feats.append([f.get("rms", 0.0), f.get("zcr", 0.0), f.get("centroid", 0.0), f.get("dur", 0.0)])
            X = np.asarray(feats, dtype=np.float32)
            mu = X.mean(axis=0)
            sig = X.std(axis=0) + 1e-6
            Xn = (X - mu) / sig

            k = self._dynamic_k(len(samples))
            km = KMeansLite(k=k, iters=24, rng=random.Random(self.rng.randint(0, 2**30)))
            labels = km.fit_predict(Xn)
            for s, cid in zip(samples, labels.tolist()):
                s.cluster_id = int(cid)

class DatasetProfile:
    """
    Style-agnostic dataset statistics to ground targets in the actual sample pool.
    Computes quantiles of key features per stem and overall.
    """
    def __init__(self, samples_by_stem: Dict[str, List[Sample]]):
        self.samples_by_stem = samples_by_stem
        self.stats: Dict[str, Dict[str, float]] = {}
        self._build()

    @staticmethod
    def _q(values: List[float], q: float) -> float:
        if not values:
            return 0.0
        return float(np.quantile(np.asarray(values, dtype=np.float32), q))

    def _build_for(self, key: str, samples: List[Sample]) -> Dict[str, float]:
        cent = [float(s.features.get("centroid", 0.0)) for s in samples]
        zcr = [float(s.features.get("zcr", 0.0)) for s in samples]
        dur = [float(s.features.get("dur", s.duration)) for s in samples]
        rms = [float(s.features.get("rms", 0.0)) for s in samples]

        return {
            "centroid_q20": self._q(cent, 0.20),
            "centroid_q50": self._q(cent, 0.50),
            "centroid_q80": self._q(cent, 0.80),
            "zcr_q50": self._q(zcr, 0.50),
            "dur_q20": self._q(dur, 0.20),
            "dur_q50": self._q(dur, 0.50),
            "dur_q80": self._q(dur, 0.80),
            "rms_q50": self._q(rms, 0.50),
            "count": float(len(samples)),
        }

    def _build(self):
        all_samples: List[Sample] = []
        for st, lst in self.samples_by_stem.items():
            self.stats[st] = self._build_for(st, lst)
            all_samples.extend(lst)
        self.stats["_all"] = self._build_for("_all", all_samples)


class PaletteLock:
    """
    Maintains a small set of 'active clusters' per stem. This is the main mechanism
    that makes the system settle into material (repetition) without any step grid.
    Lock strength is driven by state.commitment (0..1).
    """
    def __init__(self, rng: random.Random):
        self.rng = rng
        self.active_clusters: Dict[str, List[int]] = {}
        self._last_commitment_bucket: Optional[int] = None

    @staticmethod
    def _commitment_bucket(c: float) -> int:
        # coarse bucket to avoid thrashing cluster sets every frame
        return int(np.clip(math.floor(c * 6), 0, 5))

    def refresh_if_needed(self, stem: str, samples: List[Sample], commitment: float):
        if not samples:
            self.active_clusters[stem] = []
            return

        b = self._commitment_bucket(commitment)
        # if bucket unchanged and we have clusters, keep
        if self._last_commitment_bucket == b and stem in self.active_clusters and self.active_clusters[stem]:
            return

        self._last_commitment_bucket = b

        # dynamic size: higher commitment => fewer clusters => more material reuse
        # (no genre: just a control law)
        unique_clusters = sorted({int(s.cluster_id) for s in samples if s.cluster_id >= 0})
        if not unique_clusters:
            self.active_clusters[stem] = []
            return

        # k decreases as commitment increases
        max_k = max(1, int(round(math.sqrt(len(unique_clusters)))))
        k = int(np.clip(round((1.0 - commitment) * max_k) + 1, 1, max_k))

        # choose k clusters deterministically via rng
        chosen = unique_clusters[:]
        self.rng.shuffle(chosen)
        self.active_clusters[stem] = chosen[:k]

    def is_allowed(self, stem: str, cluster_id: int, commitment: float) -> bool:
        clusters = self.active_clusters.get(stem, [])
        if not clusters:
            return True
        # commitment increases probability of staying in palette
        stay_prob = float(np.clip(0.15 + 0.80 * commitment, 0.0, 0.98))
        if cluster_id in clusters:
            return True
        # allow escapes sometimes
        return self.rng.random() > stay_prob
    

# -------------------- Run logging (one JSON per run) --------------------
class RunLogger:
    """
    One JSON file per run:
      {
        "run_meta": {...},
        "segments": [
          { "segment_meta": {...}, "events": [...] },
          ...
        ]
      }
    """
    def __init__(self, run_meta: Dict[str, Any], runs_dir: Path = Path("runs")):
        runs_dir.mkdir(exist_ok=True)
        ts = time.strftime("%Y%m%d_%H%M%S")
        self.path = runs_dir / f"run_{ts}.json"
        self.run_meta = dict(run_meta)
        self.segments: List[Dict[str, Any]] = []
        self._cur: Optional[Dict[str, Any]] = None
        self._seg_index = 0

    def start_segment(self, segment_meta: Dict[str, Any]):
        if self._cur is not None:
            self._cur["segment_meta"]["ended_at"] = time.time()
        seg = {
            "segment_meta": {
                "segment_index": int(self._seg_index),
                "created_at": time.time(),
                **segment_meta,
            },
            "events": [],
        }
        self.segments.append(seg)
        self._cur = seg
        self._seg_index += 1

    def log_event(self, event: Dict[str, Any]):
        if self._cur is None:
            self.start_segment({"reason": "implicit_init"})
        self._cur["events"].append(event)

    def finalize(self):
        if self._cur is not None:
            self._cur["segment_meta"]["ended_at"] = time.time()
        out = {"run_meta": self.run_meta, "segments": self.segments}
        with open(self.path, "w") as f:
            json.dump(out, f, indent=2)
        return self.path


# -------------------- Agentic core --------------------
@dataclass
class GlobalState:
    """Continuously-adapted musical control signals (0..1ish)."""
    tempo_bpm: float
    energy: float
    tension: float
    density: float
    brightness: float
    novelty: float
    coherence: float
    commitment: float  # NEW: palette lock strength / willingness to repeat material

    def clamp(self):
        self.tempo_bpm = float(np.clip(self.tempo_bpm, 40.0, 190.0))
        self.energy = float(np.clip(self.energy, 0.0, 1.0))
        self.tension = float(np.clip(self.tension, 0.0, 1.0))
        self.density = float(np.clip(self.density, 0.0, 1.0))
        self.brightness = float(np.clip(self.brightness, 0.0, 1.0))
        self.novelty = float(np.clip(self.novelty, 0.0, 1.0))
        self.coherence = float(np.clip(self.coherence, 0.0, 1.0))
        self.commitment = float(np.clip(self.commitment, 0.0, 1.0))


class Critic:
    """
    Style-agnostic critic:
    - penalizes too repetitive (entropy too low) AND too diverse (entropy too high)
    - adapts entropy target band from running history (so it doesn't bake in a style)
    """
    def __init__(self, window_events: int = 256):
        self.window_events = max(64, int(window_events))

        # running stats for entropy (adaptive target band)
        self._ent_mu = 2.5
        self._ent_var = 1.0
        self._alpha = 0.05  # smoothing; not user-facing

        # running stats for event rate
        self._rate_mu = 6.0
        self._rate_var = 4.0

    @staticmethod
    def _entropy(items: List[Any]) -> float:
        if not items:
            return 0.0
        c = Counter(items)
        n = float(len(items))
        p = np.array([v / n for v in c.values()], dtype=np.float32)
        return float(-np.sum(p * np.log2(p + 1e-12)))

    def _update_running(self, mu: float, var: float, x: float) -> Tuple[float, float]:
        a = self._alpha
        d = x - mu
        mu2 = mu + a * d
        var2 = (1.0 - a) * var + a * (d * d)
        return float(mu2), float(max(1e-6, var2))

    def analyze(self, recent_events: List[Dict[str, Any]]) -> Dict[str, float]:
        ev = recent_events[-self.window_events :]
        if not ev:
            return {
                "boredom": 0.25,
                "chaos": 0.0,
                "repetition": 0.0,
                "diversity": 0.0,
                "event_rate": 0.0,
                "ent_mix": 0.0,
            }

        names = [e.get("sample_name", "") for e in ev]
        clusters = [e.get("cluster_id", -1) for e in ev]
        stems = [e.get("stem", "") for e in ev]
        times = [float(e.get("t_sec", 0.0)) for e in ev]

        ent_names = self._entropy(names)
        ent_clusters = self._entropy(clusters)
        ent_stems = self._entropy(stems)

        # Mix entropy: names+clusters are "material diversity"
        ent_mix = float(0.55 * ent_names + 0.45 * ent_clusters)

        t0, t1 = min(times), max(times)
        dt = max(1e-6, t1 - t0)
        event_rate = float(len(ev) / dt)

        # Update running baselines
        self._ent_mu, self._ent_var = self._update_running(self._ent_mu, self._ent_var, ent_mix)
        self._rate_mu, self._rate_var = self._update_running(self._rate_mu, self._rate_var, event_rate)

        ent_sigma = math.sqrt(self._ent_var)
        rate_sigma = math.sqrt(self._rate_var)

        # Adaptive "good band" for entropy around running mean
        lo = self._ent_mu - 0.75 * ent_sigma
        hi = self._ent_mu + 0.75 * ent_sigma
        band = max(0.25, hi - lo)

        # two-sided penalties:
        too_low = float(np.clip((lo - ent_mix) / band, 0.0, 1.0))   # too repetitive
        too_high = float(np.clip((ent_mix - hi) / band, 0.0, 1.0))  # too diverse

        repetition = too_low
        diversity = too_high

        # event-rate relative to baseline (also two-sided, but "too high" matters more for chaos)
        rate_hi = self._rate_mu + 1.0 * rate_sigma
        rate_lo = max(0.0, self._rate_mu - 1.0 * rate_sigma)
        rate_band = max(0.5, rate_hi - rate_lo)
        rate_too_high = float(np.clip((event_rate - rate_hi) / rate_band, 0.0, 1.0))
        rate_too_low = float(np.clip((rate_lo - event_rate) / rate_band, 0.0, 1.0))

        # boredom: too repetitive OR too sparse (but not punishing sparsity as harshly)
        boredom = float(np.clip(0.70 * repetition + 0.30 * rate_too_low, 0.0, 1.0))

        # chaos: too diverse OR too dense + too many stems at once (stem entropy)
        chaos = float(np.clip(0.55 * diversity + 0.30 * rate_too_high + 0.15 * np.clip(ent_stems / 2.0, 0.0, 1.0), 0.0, 1.0))

        return {
            "boredom": boredom,
            "chaos": chaos,
            "repetition": repetition,  # 0..1 => "entropy too low"
            "diversity": diversity,    # 0..1 => "entropy too high"
            "event_rate": event_rate,
            "ent_mix": ent_mix,
            "ent_mu": self._ent_mu,
            "ent_sigma": ent_sigma,
            "rate_mu": self._rate_mu,
            "rate_sigma": rate_sigma,
        }

class Director:
    """
    Style-agnostic regime scheduler.
    No named sections. It samples new target vectors from:
    - dataset profile (grounded ranges)
    - current state (continuity)
    - critic feedback (self-correction)
    """
    def __init__(self, rng: random.Random, dataset: DatasetProfile):
        self.rng = rng
        self.dataset = dataset
        self.segment_ends_at: float = 0.0
        self.regime_id: int = 0
        self._current_targets: Optional[Dict[str, float]] = None

    def _rand_smooth(self, x: float, spread: float) -> float:
        # small symmetric noise, bounded
        return float(np.clip(x + self.rng.uniform(-spread, spread), 0.0, 1.0))

    def maybe_transition(self, now_sec: float, state: GlobalState, critic: Dict[str, float]):
        # end segment by time or if critic says we're out of bounds
        if now_sec >= self.segment_ends_at or critic.get("chaos", 0.0) > 0.88 or critic.get("boredom", 0.0) > 0.88:
            self._transition(now_sec, state, critic)

    def _transition(self, now_sec: float, state: GlobalState, critic: Dict[str, float]):
        self.regime_id += 1

        # Segment duration emerges from coherence/commitment (stable regimes last longer),
        # shortened by chaos/boredom spikes.
        chaos = critic.get("chaos", 0.0)
        boredom = critic.get("boredom", 0.0)
        base = 8.0 + 26.0 * (0.5 * state.coherence + 0.5 * state.commitment)
        base *= (1.0 - 0.65 * chaos)
        base *= (1.0 - 0.35 * boredom)
        dur = float(np.clip(self.rng.uniform(0.8 * base, 1.2 * base), 5.0, 60.0))
        self.segment_ends_at = now_sec + dur

        # Sample new targets near current state (continuity), not from archetypes.
        # Then bend them using critic signals.
        t = {}

        # Tempo: drift gently; stronger drift when novelty is high
        tempo_drift = 0.03 + 0.10 * state.novelty
        t["tempo_bpm"] = float(np.clip(state.tempo_bpm * (1.0 + self.rng.uniform(-tempo_drift, tempo_drift)), 40.0, 190.0))

        # Base target sampling (small random walk in normalized space)
        t["energy"] = self._rand_smooth(state.energy, 0.18)
        t["tension"] = self._rand_smooth(state.tension, 0.16)
        t["density"] = self._rand_smooth(state.density, 0.20)
        t["brightness"] = self._rand_smooth(state.brightness, 0.22)
        t["novelty"] = self._rand_smooth(state.novelty, 0.22)
        t["coherence"] = self._rand_smooth(state.coherence, 0.18)
        t["commitment"] = self._rand_smooth(state.commitment, 0.20)

        # Critic feedback:
        repetition = critic.get("repetition", 0.0)  # entropy too low
        diversity = critic.get("diversity", 0.0)    # entropy too high
        chaos = critic.get("chaos", 0.0)
        boredom = critic.get("boredom", 0.0)

        # If too repetitive -> decrease commitment/coherence, increase novelty a bit
        t["commitment"] = float(np.clip(t["commitment"] - 0.55 * repetition, 0.0, 1.0))
        t["coherence"] = float(np.clip(t["coherence"] - 0.30 * repetition, 0.0, 1.0))
        t["novelty"] = float(np.clip(t["novelty"] + 0.45 * repetition, 0.0, 1.0))

        # If too diverse -> increase commitment/coherence, reduce novelty/density a bit
        t["commitment"] = float(np.clip(t["commitment"] + 0.65 * diversity, 0.0, 1.0))
        t["coherence"] = float(np.clip(t["coherence"] + 0.45 * diversity, 0.0, 1.0))
        t["novelty"] = float(np.clip(t["novelty"] - 0.55 * diversity, 0.0, 1.0))
        t["density"] = float(np.clip(t["density"] - 0.35 * diversity, 0.0, 1.0))

        # If chaotic -> more stabilization
        t["coherence"] = float(np.clip(t["coherence"] + 0.40 * chaos, 0.0, 1.0))
        t["density"] = float(np.clip(t["density"] - 0.35 * chaos, 0.0, 1.0))
        t["tension"] = float(np.clip(t["tension"] - 0.20 * chaos, 0.0, 1.0))

        # If bored -> explore a bit
        t["novelty"] = float(np.clip(t["novelty"] + 0.30 * boredom, 0.0, 1.0))
        t["brightness"] = float(np.clip(t["brightness"] + 0.18 * boredom, 0.0, 1.0))

        self._current_targets = t

    def current_targets(self) -> Dict[str, float]:
        # if no targets yet, create an initial transition
        if self._current_targets is None:
            # will be filled on first maybe_transition call if needed;
            # keep safe fallback.
            return {}
        return dict(self._current_targets)

    @property
    def name(self) -> str:
        # no style names; just a stable identifier
        return f"regime_{self.regime_id}"

class Memory:
    """Recent-history and motif-like traces (lightweight)."""
    def __init__(self, per_voice: int = 96):
        self.per_voice = max(32, int(per_voice))
        self.recent_samples: Dict[str, deque] = {}      # stem -> deque(sample_name)
        self.recent_clusters: Dict[str, deque] = {}     # stem -> deque(cluster_id)

    def note(self, stem: str, sample_name: str, cluster_id: int):
        if stem not in self.recent_samples:
            self.recent_samples[stem] = deque(maxlen=self.per_voice)
            self.recent_clusters[stem] = deque(maxlen=self.per_voice)
        self.recent_samples[stem].append(sample_name)
        self.recent_clusters[stem].append(int(cluster_id))

    def recency_penalty(self, stem: str, sample_name: str) -> float:
        """0..1 penalty (higher means 'played too recently')."""
        dq = self.recent_samples.get(stem)
        if not dq:
            return 0.0
        # penalty based on how close it appears to the end
        # (linear scan is fine at this scale)
        for i in range(len(dq) - 1, -1, -1):
            if dq[i] == sample_name:
                rec = (len(dq) - 1 - i)
                # very recent => high penalty; older => low
                return float(np.clip(1.0 - rec / max(1.0, len(dq)), 0.0, 1.0))
        return 0.0


# -------------------- Voices (event-based) --------------------
class Voice:
    """
    A voice is a policy that generates events over continuous time, influenced by:
    - global state (energy/tension/density/brightness/novelty/coherence)
    - its own role (stem type)
    - memory (avoid repetition or embrace it depending on coherence)
    - palette (clusters/timbre)
    """
    def __init__(self, stem: str, channel: int, samples: List[Sample], rng: random.Random, memory: Memory):
        self.stem = stem
        self.channel = int(channel)
        self.samples = samples
        self.rng = rng
        self.memory = memory

        self.next_time_sec: float = 0.0

        # internal drift (agentic "personality" per voice)
        self.bias_brightness = self.rng.random()
        self.bias_activity = self.rng.random()

    def _role_weights(self) -> Dict[str, float]:
        # Not hardcoded as final values: used as priors, mixed with state dynamically.
        if self.stem == "drums":
            return {"activity": 1.0, "brightness": 0.55, "pitch": 0.05}
        if self.stem == "bass":
            return {"activity": 0.55, "brightness": 0.25, "pitch": 0.15}
        if self.stem == "vocals":
            return {"activity": 0.35, "brightness": 0.45, "pitch": 0.25}
        return {"activity": 0.45, "brightness": 0.55, "pitch": 0.20}

    def _seconds_per_beat(self, state: GlobalState) -> float:
        return 60.0 / max(1.0, state.tempo_bpm)

    def _sample_density_interval(self, state: GlobalState) -> float:
        """
        Convert desired density to an inter-onset interval distribution.
        No fixed step grid: we draw IOIs with a soft pulse preference.
        """
        spb = self._seconds_per_beat(state)

        # Activity target scales with global density and voice bias.
        w = self._role_weights()
        act = float(np.clip(0.10 + 0.90 * state.density, 0.0, 1.0))
        act = float(np.clip(act * (0.55 + 0.90 * w["activity"]) * (0.60 + 0.80 * self.bias_activity), 0.0, 1.0))

        # Map activity to expected IOI in beats (higher activity => smaller IOI).
        # We do this continuously: beats_per_event ~ exp curve.
        beats_per_event = float(np.clip(2.0 * math.exp(-2.2 * act) + 0.10, 0.08, 3.5))

        # Soft pulse: prefer simple fractions but not forced.
        # Instead of hardcoding a set of subdivisions, we "magnetize" to near-rational multiples of spb.
        base_ioi = beats_per_event * spb

        # Add variability driven by tension and novelty.
        var = 0.15 + 0.65 * state.tension + 0.35 * state.novelty
        jitter = self.rng.lognormvariate(0.0, 0.25 + 0.40 * var)  # >0 multiplier
        ioi = base_ioi * float(np.clip(jitter, 0.35, 3.0))

        # Coherence pulls closer to pulse; novelty pushes away.
        coherence = state.coherence
        pulse = spb / max(0.25, (1.0 + 3.0 * act))  # a "micro pulse" not a grid
        # "magnet" ioi towards nearest multiple of pulse
        m = max(1, int(round(ioi / max(1e-6, pulse))))
        magnet = m * pulse
        pull = float(np.clip(0.15 + 0.75 * coherence - 0.30 * state.novelty, 0.0, 1.0))
        ioi = (1.0 - pull) * ioi + pull * magnet

        return float(np.clip(ioi, 0.04, 3.5))

    def _choose_sample(self, state: GlobalState) -> Optional[Sample]:
        if not self.samples:
            return None

        # palette lock refresh (per stem)
        # (PaletteLock is owned by Agent, so Voice expects self.palette to exist; wired in Agent below.)
        self.palette.refresh_if_needed(self.stem, self.samples, state.commitment)

        w = self._role_weights()

        # desire brightness is still continuous and state-driven
        desire = float(np.clip(0.55 * state.brightness + 0.25 * self.bias_brightness + 0.20 * w["brightness"], 0.0, 1.0))

        # novelty controls how hard we punish repeats; commitment controls palette restriction
        recency_weight = float(np.clip(state.novelty * (1.0 - 0.35 * state.coherence), 0.0, 1.0))

        tries = min(16, len(self.samples))
        best = None
        best_score = -1e9

        for _ in range(tries):
            s = self.samples[self.rng.randrange(len(self.samples))]

            # palette lock: mostly stay in active clusters when commitment is high
            if not self.palette.is_allowed(self.stem, int(s.cluster_id), state.commitment):
                continue

            f = s.features
            centroid = float(f.get("centroid", 0.0))
            bright = float(np.clip(centroid / 8000.0, 0.0, 1.0))
            bright_score = -abs(bright - desire)

            # repetition penalty only matters when novelty is high
            rep_pen = self.memory.recency_penalty(self.stem, s.name)
            rep_score = -(rep_pen * recency_weight)

            # duration preference stays state-driven (no style)
            dur = float(f.get("dur", s.duration))
            dur_pref = float(np.clip(0.35 + 0.80 * (1.0 - state.tension), 0.0, 1.0))
            target = 0.08 + 0.85 * dur_pref
            dur_score = -abs(np.clip(dur, 0.02, 3.0) - target)

            # slight preference for coherence: if coherence is high, reward reuse within palette (gentle)
            in_palette = int(s.cluster_id) in set(self.palette.active_clusters.get(self.stem, []))
            palette_bonus = (0.08 * state.coherence) if in_palette else 0.0

            score = 1.20 * bright_score + 0.90 * rep_score + 0.55 * dur_score + palette_bonus + 0.03 * self.rng.random()

            if score > best_score:
                best_score = score
                best = s

        # fallback if everything got filtered out
        if best is None:
            best = self.samples[self.rng.randrange(len(self.samples))]

        return best

    def _render_params(self, s: Sample, state: GlobalState) -> RenderParams:
        w = self._role_weights()

        # Gain: normalize by sample rms; then scale by energy and role.
        rms = float(s.features.get("rms", 0.08))
        # target loudness rises with energy but is tempered by coherence (more coherent => less brute force)
        loud = 0.06 + 0.18 * state.energy * (0.65 + 0.35 * (1.0 - state.coherence))
        role_scale = 0.85 + 0.45 * w["activity"]
        gain = float(np.clip((loud / max(1e-4, rms)) * role_scale, 0.02, 1.2))

        # Brightness -> filter cutoff (dynamic, not hard fixed to a single value).
        # Map 0..1 => 400..20000-ish, with role modulation.
        bright = float(np.clip(0.70 * state.brightness + 0.30 * w["brightness"], 0.0, 1.0))
        cutoff = 400.0 * (20000.0 / 400.0) ** bright  # exponential mapping
        cutoff = float(np.clip(cutoff, 200.0, 20000.0))

        # Reverse and drive are tension/novelty gestures.
        reverse_p = float(np.clip(0.03 + 0.25 * state.tension + 0.15 * state.novelty, 0.0, 0.6))
        reverse = self.rng.random() < reverse_p

        drive = float(np.clip(1.2 + 2.6 * state.energy + 1.2 * state.tension, 1.0, 6.0))

        # Pitch is subtle: derived from tension/novelty and role. Keep small to preserve sample identity.
        pitch_depth = 0.35 * w["pitch"] + 0.25 * state.novelty + 0.15 * state.tension
        semitone = float(np.clip(self.rng.uniform(-3.0, 3.0) * pitch_depth, -6.0, 6.0))

        # Envelope: tension -> sharper; release -> longer tails.
        attack = 0.001 + 0.020 * (1.0 - state.tension) * (0.25 + 0.75 * (1.0 - state.energy))
        release = 0.015 + 0.250 * (1.0 - state.tension) * (0.35 + 0.65 * (1.0 - state.energy))
        fade = float(np.clip(0.002 + 0.015 * (1.0 - state.tension), 0.002, 0.02))

        return RenderParams(
            gain=gain,
            semitone=semitone,
            lowpass_hz=cutoff,
            reverse=reverse,
            drive=drive,
            fade_s=fade,
            env_attack_s=float(attack),
            env_release_s=float(release),
        )

    def plan_next(self, now_sec: float, state: GlobalState) -> Optional[Tuple[float, Sample, RenderParams]]:
        if now_sec < self.next_time_sec:
            return None

        s = self._choose_sample(state)
        if s is None:
            # If a voice has no samples, schedule far away and stay silent.
            self.next_time_sec = now_sec + 5.0
            return None

        params = self._render_params(s, state)
        t = now_sec

        # schedule next onset time
        ioi = self._sample_density_interval(state)
        # microtiming: small +/- jitter; coherence reduces jitter
        jitter = (0.003 + 0.020 * state.novelty) * (1.0 - 0.75 * state.coherence)
        t_next = t + ioi + self.rng.uniform(-jitter, jitter)

        self.next_time_sec = max(now_sec + 0.01, t_next)

        return (t, s, params)


# -------------------- Renderer --------------------
class Renderer:
    """Turns (Sample, RenderParams) into a mono float32 buffer at engine SR."""
    def __init__(self, sr: int):
        self.sr = int(sr)

    def render(self, s: Sample, p: RenderParams) -> np.ndarray:
        sig = np.asarray(s.data, dtype=np.float32).copy()
        if p.reverse:
            sig = sig[::-1]

        if s.sr != self.sr:
            sig = resample_linear(sig, s.sr / self.sr)

        # pitch shift (via resampling)
        pr = semitone_to_ratio(p.semitone)
        if pr != 1.0:
            sig = resample_linear(sig, pr)

        sig = to_mono(sig)
        sig *= float(p.gain)

        sig = lowpass_1pole(sig, p.lowpass_hz, self.sr)

        # dynamic envelope
        env = envelope_perc(len(sig), self.sr, p.env_attack_s, p.env_release_s)
        sig *= env

        # fades (anti-click)
        fade_samps = int(round(p.fade_s * self.sr))
        sig = apply_fade(sig, fade_samps)

        # gentle saturation
        sig = soft_clip(sig, p.drive)

        return sig.astype(np.float32, copy=False)


# -------------------- Scheduler/Planner --------------------
class AtomicInt:
    def __init__(self, v: int = 0):
        self._v = int(v)
        self._lock = threading.Lock()

    def get(self) -> int:
        with self._lock:
            return int(self._v)

    def set(self, v: int):
        with self._lock:
            self._v = int(v)


class Agent:
    """Coordinates Director/Critic/Memory/Voices into a coherent planning API."""
    def __init__(
        self,
        voices: List[Voice],
        sr: int,
        rng: random.Random,
        logger: RunLogger,
        dataset: DatasetProfile,  # NEW
    ):
        self.voices = voices
        self.sr = int(sr)
        self.rng = rng
        self.logger = logger

        # State initialization is *dynamic* from RNG + dataset hints (centroid distribution).
        # We avoid forcing the user to pick bpm/density/etc.
        self.state = GlobalState(
            tempo_bpm=float(self.rng.uniform(70.0, 150.0)),
            energy=float(self.rng.random()),
            tension=float(self.rng.random() * 0.6),
            density=float(self.rng.random()),
            brightness=float(self.rng.random()),
            novelty=float(self.rng.uniform(0.15, 0.85)),
            coherence=float(self.rng.uniform(0.35, 0.90)),
            commitment=float(self.rng.uniform(0.25, 0.85)),  # NEW
        )
        self.state.clamp()

        self.critic = Critic()
        self.dataset = dataset
        self.director = Director(self.rng, dataset=self.dataset)
        self.memory = voices[0].memory if voices else Memory()
        self.renderer = Renderer(sr=self.sr)

        self.recent_events: List[Dict[str, Any]] = []
        self._last_state_update: float = 0.0

        self.palette = PaletteLock(self.rng)
        # wire palette into each voice (so Voice._choose_sample can use it)
        for v in self.voices:
            v.palette = self.palette

        # Ensure we have an initial regime/targets right away
        self.director.maybe_transition(now_sec=0.0, state=self.state, critic={})

        # Start first segment immediately.
        self.logger.start_segment(self._segment_meta(reason="init"))

        # GUI Stuff
        self._lock = threading.Lock()
        self._last_critic: Dict[str, float] = {}
        self._last_event: Optional[Dict[str, Any]] = None
        self._event_count_total = 0
    
    def snapshot(self) -> Dict[str, Any]:
        """Thread-safe snapshot for GUI/monitoring."""
        with self._lock:
            return {
                "time": time.time(),
                "segment": self.director.name,
                "segment_ends_at": float(self.director.segment_ends_at),
                "state": {
                    "tempo_bpm": float(self.state.tempo_bpm),
                    "energy": float(self.state.energy),
                    "tension": float(self.state.tension),
                    "density": float(self.state.density),
                    "brightness": float(self.state.brightness),
                    "novelty": float(self.state.novelty),
                    "coherence": float(self.state.coherence),
                    "commitment": float(self.state.commitment),
                },
                "critic": dict(self._last_critic),
                "events_total": int(self._event_count_total),
                "recent_events_len": int(len(self.recent_events)),
                "last_event": dict(self._last_event) if self._last_event else None,
            }
    
    def _segment_meta(self, reason: str) -> Dict[str, Any]:
        return {
            "reason": reason,
            "segment_name": self.director.name,  # style-agnostic regime id string
            "segment_ends_at": float(self.director.segment_ends_at),
            "state": {
                "tempo_bpm": self.state.tempo_bpm,
                "energy": self.state.energy,
                "tension": self.state.tension,
                "density": self.state.density,
                "brightness": self.state.brightness,
                "novelty": self.state.novelty,
                "coherence": self.state.coherence,
                "commitment": self.state.commitment,
            },
        }

    def _smooth_state_towards(self, targets: Dict[str, float], dt: float):
        # dt-scaled one-pole smoothing, with per-parameter adaptability.
        # This is how “everything is dynamically calculated”: the Director sets ranges,
        # and the system glides rather than stepping.
        a = float(np.clip(0.08 + 0.22 * dt, 0.02, 0.45))
        for k, v in targets.items():
            cur = getattr(self.state, k)
            setattr(self.state, k, float((1.0 - a) * cur + a * float(v)))
        self.state.clamp()

    def _update_state(self, now_sec: float):
        # update at a modest rate; planning runs often
        if now_sec - self._last_state_update < 1.0:
            return
        dt = now_sec - self._last_state_update
        self._last_state_update = now_sec

        critic = self.critic.analyze(self.recent_events)
        # store critic for the GUI (thread-safe)
        with self._lock:
            self._last_critic = dict(critic)

        self.director.maybe_transition(now_sec, self.state, critic)

        # Start new segment in log if regime id/name changed
        prev_name = self.logger.segments[-1]["segment_meta"].get("segment_name") if self.logger.segments else None
        cur_name = self.director.name
        if cur_name != prev_name:
            self.logger.start_segment(self._segment_meta(reason="transition"))

        targets = self.director.current_targets()

        # If director hasn't produced targets yet, just keep drifting mildly
        if not targets:
            targets = {
                "tempo_bpm": float(self.state.tempo_bpm),
                "energy": float(self.state.energy),
                "tension": float(self.state.tension),
                "density": float(self.state.density),
                "brightness": float(self.state.brightness),
                "novelty": float(self.state.novelty),
                "coherence": float(self.state.coherence),
                "commitment": float(self.state.commitment),
            }

        # Smooth toward targets
        self._smooth_state_towards(targets, dt=min(2.0, dt))

        # Critic feedback loops (agentic self-correction):
        boredom = critic.get("boredom", 0.0)
        chaos = critic.get("chaos", 0.0)

        # boredom -> raise novelty/brightness/density slightly
        targets["novelty"] = float(np.clip(targets.get("novelty", self.state.novelty) + 0.35 * boredom, 0.0, 1.0))
        targets["brightness"] = float(np.clip(targets.get("brightness", self.state.brightness) + 0.18 * boredom, 0.0, 1.0))
        targets["density"] = float(np.clip(targets.get("density", self.state.density) + 0.22 * boredom, 0.0, 1.0))

        # chaos -> increase coherence, reduce density and tension a bit
        targets["coherence"] = float(np.clip(targets.get("coherence", self.state.coherence) + 0.35 * chaos, 0.0, 1.0))
        targets["density"] = float(np.clip(targets.get("density", self.state.density) - 0.35 * chaos, 0.0, 1.0))
        targets["tension"] = float(np.clip(targets.get("tension", self.state.tension) - 0.20 * chaos, 0.0, 1.0))

        # Keep tempo responsive to energy but stable:
        targets["tempo_bpm"] = float(np.clip(targets.get("tempo_bpm", self.state.tempo_bpm) * (0.92 + 0.16 * self.state.energy), 40.0, 190.0))

        self._smooth_state_towards(targets, dt=min(2.0, dt))

    def _log_and_remember(self, e: Dict[str, Any]):
        with self._lock:
            self._last_event = dict(e)
            self._event_count_total += 1
        self.recent_events.append(e)
        # keep recent events bounded
        if len(self.recent_events) > 1200:
            self.recent_events = self.recent_events[-800:]

        self.logger.log_event(e)
        self.memory.note(e["stem"], e["sample_name"], int(e.get("cluster_id", -1)))

    def plan_audio_until(self, now_sample: int, until_sample: int) -> List[ScheduledAudio]:
        """
        Produce rendered audio buffers scheduled between now and until, inclusive.
        This runs in the planner thread (not the audio callback).
        """
        now_sec = now_sample / self.sr
        until_sec = until_sample / self.sr
        self._update_state(now_sec)

        out: List[ScheduledAudio] = []

        # Plan iteratively; voices generate events when their next_time_sec arrives.
        # We always clamp planning to the lookahead window.
        cursor_sec = now_sec
        # A small cap to avoid pathological loops if a voice produces micro-IOIs.
        max_events = 256

        for _ in range(max_events):
            # choose next voice event among those that are due soonest
            soonest_t = None
            soonest_voice = None
            soonest_payload = None

            for v in self.voices:
                payload = v.plan_next(cursor_sec, self.state)
                if payload is None:
                    continue
                (t, sample, params) = payload
                if t > until_sec:
                    continue
                if soonest_t is None or t < soonest_t:
                    soonest_t = t
                    soonest_voice = v
                    soonest_payload = payload

            if soonest_voice is None:
                break

            t, sample, params = soonest_payload
            start_sample = int(round(t * self.sr))
            if start_sample > until_sample:
                break

            buf = self.renderer.render(sample, params)
            sched = ScheduledAudio(
                start_sample=start_sample,
                channel=soonest_voice.channel,
                buffer=buf,
                event_meta={
                    "t_sec": float(t),
                    "start_sample": int(start_sample),
                    "stem": soonest_voice.stem,
                    "channel": int(soonest_voice.channel),
                    "sample_name": sample.name,
                    "filename": sample.filename,
                    "cluster_id": int(sample.cluster_id),
                    "params": {
                        "gain": params.gain,
                        "semitone": params.semitone,
                        "lowpass_hz": params.lowpass_hz,
                        "reverse": params.reverse,
                        "drive": params.drive,
                        "fade_s": params.fade_s,
                        "env_attack_s": params.env_attack_s,
                        "env_release_s": params.env_release_s,
                    },
                    "state": {
                        "tempo_bpm": self.state.tempo_bpm,
                        "energy": self.state.energy,
                        "tension": self.state.tension,
                        "density": self.state.density,
                        "brightness": self.state.brightness,
                        "novelty": self.state.novelty,
                        "coherence": self.state.coherence,
                    },
                    "segment": self.director.name,
                },
            )
            out.append(sched)
            self._log_and_remember(sched.event_meta)

            # advance cursor slightly so multiple voices can schedule within window
            cursor_sec = min(until_sec, t + 0.001)

        return out


class PlannerThread:
    """Schedules audio ahead of time and pushes it into a heap (start_sample-ordered)."""
    def __init__(self, agent: Agent, current_sample: AtomicInt, sr: int):
        self.agent = agent
        self.current_sample = current_sample
        self.sr = int(sr)

        self.heap: List[Tuple[int, int, ScheduledAudio]] = []
        self._heap_lock = threading.Lock()
        self._seq = 0  # deterministic tie-break for heap ordering

        self.lookahead_s = 0.75  # internal; not user-facing
        self.min_buffer_s = 0.35

        self._stop = threading.Event()
        self._thread = threading.Thread(target=self._run, daemon=True)

    def start(self):
        self._thread.start()

    def stop(self):
        self._stop.set()
        try:
            self._thread.join(timeout=1.5)
        except Exception:
            pass

    def _heap_len(self) -> int:
        with self._heap_lock:
            return len(self.heap)

    def pop_ready(self, block_start: int, block_end: int) -> List[ScheduledAudio]:
        """Pop scheduled audio with start_sample < block_end."""
        out: List[ScheduledAudio] = []
        with self._heap_lock:
            while self.heap and self.heap[0][0] < block_end:
                _, _, item = heapq.heappop(self.heap)
                # if it is too far in the past, we still play it ASAP (delay clamps in engine)
                out.append(item)
        return out

    def _push_many(self, items: List[ScheduledAudio]):
        with self._heap_lock:
            for it in items:
                heapq.heappush(self.heap, (int(it.start_sample), int(self._seq), it))
                self._seq += 1

    def _run(self):
        while not self._stop.is_set():
            now = self.current_sample.get()
            # Determine how far ahead we have events planned.
            with self._heap_lock:
                last = self.heap[-1][0] if self.heap else now

            ahead = (last - now) / self.sr
            if ahead < self.min_buffer_s:
                until = now + int(self.lookahead_s * self.sr)
                items = self.agent.plan_audio_until(now, until)
                self._push_many(items)

            time.sleep(0.01)

# -------------------- GUI -----------------------------
class StateMonitorGUI:
    def __init__(self, root: "tk.Tk", agent: Agent, on_close: Callable[[], None], refresh_ms: int = 200):
        self.root = root
        self.agent = agent
        self.on_close = on_close
        self.refresh_ms = int(refresh_ms)

        root.title("Agentic Microsample Monitor")
        root.geometry("520x520")

        self.text = tk.Text(root, wrap="word", height=30)
        self.text.pack(fill="both", expand=True)

        btn = ttk.Button(root, text="Stop", command=self._handle_close)
        btn.pack(fill="x")

        root.protocol("WM_DELETE_WINDOW", self._handle_close)

        self._tick()

    def _handle_close(self):
        try:
            self.on_close()
        finally:
            self.root.destroy()

    def _tick(self):
        snap = self.agent.snapshot()

        now = snap["time"]
        seg = snap["segment"]
        ends = snap["segment_ends_at"]
        remaining = max(0.0, ends - now) if ends else 0.0

        lines = []
        lines.append(f"Segment: {seg}   (ends in ~{remaining:.1f}s)")
        lines.append("")
        lines.append("State:")
        for k, v in snap["state"].items():
            lines.append(f"  {k:>10}: {v:.3f}" if isinstance(v, float) else f"  {k:>10}: {v}")

        lines.append("")
        lines.append("Critic:")
        if snap["critic"]:
            for k, v in snap["critic"].items():
                if isinstance(v, float):
                    lines.append(f"  {k:>12}: {v:.3f}")
                else:
                    lines.append(f"  {k:>12}: {v}")
        else:
            lines.append("  (no data yet)")

        lines.append("")
        lines.append(f"Events total: {snap['events_total']}   Recent buffer: {snap['recent_events_len']}")

        last = snap["last_event"]
        lines.append("")
        lines.append("Last event:")
        if last:
            lines.append(f"  stem: {last.get('stem')}  ch: {last.get('channel')}  cluster: {last.get('cluster_id')}")
            lines.append(f"  sample: {last.get('sample_name')}")
            p = last.get("params", {})
            lines.append(
                f"  gain={p.get('gain', 0):.3f}  lp={p.get('lowpass_hz', 0):.0f}  "
                f"semi={p.get('semitone', 0):.2f}  rev={p.get('reverse', False)}  drive={p.get('drive', 0):.2f}"
            )
        else:
            lines.append("  (none yet)")

        self.text.delete("1.0", "end")
        self.text.insert("1.0", "\n".join(lines))

        self.root.after(self.refresh_ms, self._tick)

# -------------------- Audio engine --------------------
class AudioEngine:
    def __init__(self, planner: PlannerThread, current_sample: AtomicInt, sr: int, channels: int, blocksize: int, latency: str):
        self.planner = planner
        self.current_sample = current_sample
        self.sr = int(sr)
        self.channels = int(channels)
        self.blocksize = int(blocksize)

        self.active: List[PlayEvent] = []
        self.active_lock = threading.Lock()

        self.stream = sd.OutputStream(
            samplerate=self.sr,
            blocksize=self.blocksize,
            channels=self.channels,
            dtype="float32",
            latency=latency,
            callback=self.callback,
        )
        
        self.limiter = MasterLimiter(target=0.92)

    def start(self):
        self.stream.start()

    def stop(self):
        try:
            self.stream.stop()
            self.stream.close()
        except Exception:
            pass

    def _activate(self, sched: ScheduledAudio, block_start: int):
        delay = max(0, int(sched.start_sample - block_start))
        pe = PlayEvent(buffer=sched.buffer, channel=int(sched.channel), pos=0, delay=delay)
        with self.active_lock:
            self.active.append(pe)

    def _mix_active_into(self, out: np.ndarray, start: int, end: int):
        length = end - start
        with self.active_lock:
            new_active: List[PlayEvent] = []
            for ev in self.active:
                if ev.channel >= out.shape[1]:
                    continue

                # delay handling
                seg_start = start
                seg_len = length
                if ev.delay > 0:
                    consume = min(seg_len, ev.delay)
                    ev.delay -= consume
                    if consume == seg_len:
                        new_active.append(ev)
                        continue
                    seg_start += consume
                    seg_len -= consume

                remaining = ev.buffer.shape[0] - ev.pos
                if remaining <= 0:
                    continue

                n = min(seg_len, remaining)
                out[seg_start:seg_start + n, ev.channel] += ev.buffer[ev.pos:ev.pos + n]
                ev.pos += n

                if ev.pos < ev.buffer.shape[0]:
                    new_active.append(ev)

            self.active = new_active

    def callback(self, outdata, frames, time_info, status):
        block_start = self.current_sample.get()
        block_end = block_start + frames
        self.current_sample.set(block_end)

        out = np.zeros((frames, self.channels), dtype=np.float32)

        # Fetch scheduled audio that should start within this block.
        ready = self.planner.pop_ready(block_start, block_end)
        for sched in ready:
            self._activate(sched, block_start)

        # Mix active events for the full block.
        self._mix_active_into(out, 0, frames)

        # master soft clip
        out = np.tanh(out).astype(np.float32)
        
        # master limiter
        out = self.limiter.process(out)
        
        # and keep a safety clip
        np.clip(out, -1.0, 1.0, out)
        outdata[:] = out

class MasterLimiter:
    def __init__(self, target: float = 0.92, attack: float = 0.02, release: float = 0.995):
        self.target = float(target)   # linear peak target
        self.attack = float(attack)   # how fast to reduce gain when over
        self.release = float(release) # how fast to restore gain when under
        self.gain = 1.0

    def process(self, x: np.ndarray) -> np.ndarray:
        peak = float(np.max(np.abs(x)) + 1e-12)
        desired = min(1.0, self.target / peak)

        # fast down, slow up
        if desired < self.gain:
            self.gain = (1.0 - self.attack) * self.gain + self.attack * desired
        else:
            self.gain = self.release * self.gain + (1.0 - self.release) * desired

        x *= self.gain
        return x
# -------------------- Build system --------------------
def build_system(args: argparse.Namespace):
    # seed RNGs deterministically
    if args.seed is not None:
        random.seed(args.seed)
        np.random.seed(args.seed)
    rng = random.Random(args.seed)

    if not os.path.exists(args.db_path):
        print(f"Error: Database file '{args.db_path}' not found!")
        sys.exit(1)
    if not os.path.exists(args.samples_dir):
        print(f"Error: Samples directory '{args.samples_dir}' not found!")
        sys.exit(1)

    db = SampleDatabase(args.db_path, args.samples_dir, rng)

    stems = ["drums", "bass", "other", "vocals"]
    samples_by_stem: Dict[str, List[Sample]] = {}
    for st in stems:
        lst = db.load_by_stem(st, args.samples_limit)
        samples_by_stem[st] = lst
        print(f"Loaded {len(lst)} {st} samples")
    db.close()

    total = sum(len(v) for v in samples_by_stem.values())
    if total == 0:
        print("Error: No samples loaded.")
        sys.exit(1)

    # features + clustering
    fx = FeatureExtractor(sr_target=args.sr)
    for st, lst in samples_by_stem.items():
        for s in lst:
            try:
                s.features = fx.extract(s)
            except Exception:
                s.features = {}

    Clusterer(rng).assign(samples_by_stem)
    
    dataset = DatasetProfile(samples_by_stem)

    # logging
    logger = RunLogger(
        run_meta={
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "seed": args.seed,
            "audio": {"sr": args.sr, "blocksize": args.blocksize, "channels": args.channels, "latency": args.latency},
            "db": {"db_path": args.db_path, "samples_dir": args.samples_dir, "samples_limit": args.samples_limit},
        }
    )

    # memory shared among voices
    memory = Memory(per_voice=128)

    # voices
    cmap = channel_map_for(args.channels)
    voices: List[Voice] = []
    for st in stems:
        vrng = random.Random(rng.randint(0, 2**30))
        voices.append(Voice(stem=st, channel=cmap[st], samples=samples_by_stem[st], rng=vrng, memory=memory))

    # core agent, planner, engine
    current_sample = AtomicInt(0)
    agent = Agent(voices=voices, sr=args.sr, rng=rng, logger=logger, dataset=dataset)
    planner = PlannerThread(agent=agent, current_sample=current_sample, sr=args.sr)
    engine = AudioEngine(planner=planner, current_sample=current_sample, sr=args.sr, channels=args.channels,
                         blocksize=args.blocksize, latency=args.latency)

    return logger, planner, engine, agent


# -------------------- Main --------------------
def main():
    args = parse_arguments()
    logger, planner, engine, agent = build_system(args)

    stopping = threading.Event()

    try:
        planner.start()
        engine.start()

        if _TK_AVAILABLE:
            root = tk.Tk()

            def request_stop():
                # Signal shutdown
                stopping.set()
                # Ask Tk to exit its loop cleanly (GUI thread)
                try:
                    root.quit()
                except Exception:
                    pass

            StateMonitorGUI(root, agent, on_close=request_stop, refresh_ms=200)

            # Run the GUI; returns after Stop button or window close
            root.mainloop()

        else:
            print("GUI not available (tkinter import failed). Running headless. Press Ctrl+C to stop.")
            while not stopping.is_set():
                time.sleep(0.5)

    except KeyboardInterrupt:
        pass
    finally:
        print("Stopping...")
        engine.stop()
        planner.stop()
        path = logger.finalize()
        print(f"Run log written: {path}")


if __name__ == "__main__":
    main()